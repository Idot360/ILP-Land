{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evanh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__sigma_0 is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\evanh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([653.08792288, 592.16905327]), array([316.68016218, 316.65121679]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_friedman2\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "X, y = make_friedman2(n_samples=500, noise=0, random_state=0)\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,\n",
    "        random_state=0).fit(X, y)\n",
    "gpr.score(X, y)\n",
    "gpr.predict(X[:2,:], return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [800 800 800 800 800 800 800 800 800 650 650]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evanh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but LinearDiscriminantAnalysis was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pandas as pd\n",
    "avo_TRAIN = pd.read_csv('dataset(small).csv', index_col='ID')\n",
    "# View the data!\n",
    "avo_TRAIN.head()\n",
    "#avo_TRAIN.describe()\n",
    "\n",
    "# Clean Data\n",
    "\n",
    "avo_TRAIN = avo_TRAIN.dropna(axis=0)\n",
    "\n",
    "features = [\"Population\",\"Land size\",\"Working hours\",\"Corruption\",\"Environment\",\"Income\",\"Cost of living\",\"N recreational buildings\",\"N office buildings\",\"N essential buildings\",\"N residential buildings\"]\n",
    "\n",
    "X = avo_TRAIN[features]\n",
    "y = avo_TRAIN.Happiness\n",
    "from sklearn import *\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X.to_numpy(), y.to_numpy())\n",
    "\n",
    "TEST = pd.read_csv('dataset(test).csv', index_col='ID')\n",
    "\n",
    "XforPredictions = TEST[features]\n",
    "# Make Predictions!\n",
    "yPredictions = clf.predict(XforPredictions)\n",
    "print(\"Predictions:\", yPredictions)\n",
    "# Save to CSV File!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training split:  9 ; test split:  2\n",
      "Predictions: [755.   755.5  750.75 760.   768.5  755.5  756.25 761.   761.   757.5\n",
      " 755.  ]\n"
     ]
    }
   ],
   "source": [
    "# load csvs\n",
    "import pandas as pd\n",
    "avo_TRAIN = pd.read_csv('dataset(small).csv', index_col='ID')\n",
    "# View the data!\n",
    "avo_TRAIN.head()\n",
    "#avo_TRAIN.describe()\n",
    "\n",
    "# Clean Data\n",
    "\n",
    "# Drops missing values \n",
    "avo_TRAIN = avo_TRAIN.dropna(axis=0)\n",
    "\n",
    "\n",
    "# Read more advanced ways to clean data\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "# https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "# Select data for learning\n",
    "features = [\"Population\",\"Land size\",\"Working hours\",\"Corruption\",\"Environment\",\"Income\",\"Cost of living\",\"N recreational buildings\",\"N office buildings\",\"N essential buildings\",\"N residential buildings\"]\n",
    "\n",
    "X = avo_TRAIN[features]\n",
    "y = avo_TRAIN.Happiness\n",
    "X.head()\n",
    "#y.head()\n",
    "# Regression Time!\n",
    "# Sci Kit Learn! Scientific Computing library for python\n",
    "from sklearn import *\n",
    "# Pick the regression model we want to use\n",
    "\n",
    "# Decision Tree Regression\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "# model = tree.DecisionTreeRegressor(random_state=2020)\n",
    "\n",
    "# Random Forest Regression\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "model = ensemble.RandomForestRegressor(random_state=2024, n_estimators=200)\n",
    "# Split training into some for training and some for testing\n",
    "Xtrain, Xtest, ytrain, ytest = model_selection.train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "print(\"training split: \", len(Xtrain), \"; test split: \", len(Xtest))\n",
    "# Perform regression on the data\n",
    "model.fit(X, y)\n",
    "model.score(Xtest, ytest)\n",
    "# Predict for Testing data\n",
    "# Clean Data\n",
    "\n",
    "\n",
    "# Read more advanced ways to clean data\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "# https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "# Select features\n",
    "TEST = pd.read_csv('dataset(test).csv', index_col='ID')\n",
    "\n",
    "XforPredictions = TEST[features]\n",
    "# Make Predictions!\n",
    "yPredictions = model.predict(XforPredictions)\n",
    "print(\"Predictions:\", yPredictions)\n",
    "# Save to CSV File!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitting\n",
    "\n",
    "TEST = pd.read_csv('dataset(test).csv', index_col='ID')\n",
    "\n",
    "features = [\"Population\",\"Land size\",\"Working hours\",\"Corruption\",\"Environment\",\"Income\",\"Cost of living\",\"N recreational buildings\",\"N office buildings\",\"N essential buildings\",\"N residential buildings\"]\n",
    "XforPredictions = TEST[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24280.0\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -712.25\n",
      "            Iterations: 1\n",
      "            Function evaluations: 5\n",
      "            Gradient evaluations: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " message: Optimization terminated successfully\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: -712.25\n",
       "       x: [ 1.500e+04  5.000e+03  5.000e+03  5.000e+03]\n",
       "     nit: 1\n",
       "     jac: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00]\n",
       "    nfev: 5\n",
       "    njev: 1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy as sp\n",
    "from scipy.optimize import LinearConstraint\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import fitting\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    import numpy as np\n",
    "\n",
    "    #offset = np.random.normal(0, 10, 4)\n",
    "    #parameters = np.array([x1,x2,x3,x4]) + offset\n",
    "    \n",
    "    c1, c2, c3, c4, c5, c6, c7 = CONSTANTS\n",
    "    x1, x2, x3, x4 = x\n",
    "    return -1*MODEL.predict(np.array([c1, c2, c3, c4, c5, c6, c7, x1, x2, x3, x4]).reshape(1,-1))\n",
    "\n",
    "\n",
    "global CONSTANTS\n",
    "CONSTANTS = [830,1214,340,300,500,925,1080]\n",
    "\n",
    "global MODEL\n",
    "MODEL = fitting.main()\n",
    "\n",
    "\n",
    "buildings_max = CONSTANTS[1]/0.05\n",
    "print(buildings_max)\n",
    "\n",
    "#cons = ({'type': 'ineq', 'fun': lambda x:  x[0] - 2 * x[1] + 2},\n",
    "#    {'type': 'ineq', 'fun': lambda x: -x[0] - 2 * x[1] + 6},\n",
    "#    {'type': 'ineq', 'fun': lambda x: -x[0] - 2 * x[1] + 6},\n",
    "#    {'type': 'ineq', 'fun': lambda x: -x[0] + 2 * x[1] + 2})\n",
    "cons = ()\n",
    "    \n",
    "bnds = ((1, buildings_max), (1, buildings_max), (1, buildings_max), (1, buildings_max))\n",
    "\n",
    "minimize(f, [15000, 5000, 5000, 5000], bounds=bnds, constraints=cons, method='SLSQP', options={\"disp\":True})\n",
    "#minimize(f, [15000, 5000, 5000, 5000], method='BFGS', options={'gtol': 1e-1, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.0\n",
      "            Iterations: 2\n",
      "            Function evaluations: 7\n",
      "            Gradient evaluations: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " message: Optimization terminated successfully\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: 0.0\n",
       "       x: [ 1.200e+01 -9.810e+02]\n",
       "     nit: 2\n",
       "     jac: [ 1.490e-08  1.490e-08]\n",
       "    nfev: 7\n",
       "    njev: 2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    x1, x2 = x\n",
    "    return (x1-12)**2 + (x2+981)**2\n",
    "\n",
    "minimize(f, (1, 1), method=\"SLSQP\", options={\"disp\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             6.000000\n",
       "Population                   510.909091\n",
       "Land size                    832.909091\n",
       "Working hours                308.818182\n",
       "Corruption                   272.727273\n",
       "Environment                  609.090909\n",
       "Income                       884.181818\n",
       "Cost of living               986.545455\n",
       "N recreational buildings     672.727273\n",
       "N office buildings          3954.545455\n",
       "N essential buildings       1602.272727\n",
       "N residential buildings     1536.363636\n",
       "Happiness                    754.545455\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"dataset(small).csv\")\n",
    "df.mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
